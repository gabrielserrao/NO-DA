{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d052f511",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058b660f",
   "metadata": {},
   "source": [
    "https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b3ca72",
   "metadata": {},
   "source": [
    "### 1-variable input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "498c2df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output = tensor(9., grad_fn=<AddBackward0>) \n",
      "\n",
      "Gradients:\n",
      "d(output)/d(a) = tensor(4.)\n",
      "d(output)/d(b) = tensor(1.)\n",
      "d(output)/d(input) = tensor(2.)\n"
     ]
    }
   ],
   "source": [
    "class Mymodel(nn.Module): \n",
    "    def __init__(self, a, b):\n",
    "        super().__init__()\n",
    "        self.a = nn.Parameter(torch.tensor(a))\n",
    "        self.b = nn.Parameter(torch.tensor(b))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.a*x + self.b\n",
    "\n",
    "# Instantiate the model\n",
    "mymodel = Mymodel(a = 2., b = 1.)\n",
    "\n",
    "# Create input and enable gradient calculation\n",
    "input_data = torch.tensor(4.)\n",
    "input_data.requires_grad = True\n",
    "#input_data = torch.tensor([4.,5.], requires_grad = True)\n",
    "\n",
    "# Call the forward model\n",
    "output_data = mymodel(input_data)\n",
    "print('output =', output_data, '\\n')\n",
    "\n",
    "# Calculate the gradients\n",
    "mymodel.zero_grad() # Clear any existing gradients\n",
    "output_data.backward()\n",
    "print('Gradients:')\n",
    "print('d(output)/d(a) =',mymodel.a.grad)\n",
    "print('d(output)/d(b) =',mymodel.b.grad)\n",
    "print('d(output)/d(input) =',input_data.grad)    \n",
    "\n",
    "# obj = a*x + b\n",
    "# d(obj)/d(a) = x\n",
    "# d(obj)/d(b) = 1.\n",
    "# d(obj)/d(x) = a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c684dfa5",
   "metadata": {},
   "source": [
    "###  n-variable input and 1-variable output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "129dc515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output = tensor(24., grad_fn=<AddBackward0>) \n",
      "\n",
      "Gradients:\n",
      "d(output)/d(a) = tensor([4., 5.])\n",
      "d(output)/d(b) = tensor(1.)\n",
      "d(output)/d(input) = tensor([2., 3.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Mymodel(nn.Module): \n",
    "    def __init__(self, a, b):\n",
    "        super().__init__()\n",
    "        self.a = nn.Parameter(torch.tensor(a))\n",
    "        self.b = nn.Parameter(torch.tensor(b))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return torch.sum(self.a*x) + self.b\n",
    "\n",
    "# Instantiate the model\n",
    "mymodel = Mymodel(a = [2.,3.], b = 1.)\n",
    "\n",
    "# Create input and enable gradient calculation\n",
    "input_data = torch.tensor([4.,5.])\n",
    "input_data.requires_grad = True\n",
    "#input_data = torch.tensor([4.,5.], requires_grad = True)\n",
    "\n",
    "# Call the forward model\n",
    "output_data = mymodel(input_data)\n",
    "print('output =', output_data, '\\n')\n",
    "\n",
    "# Calculate the gradients\n",
    "mymodel.zero_grad() # Clear any existing gradients\n",
    "output_data.backward()\n",
    "print('Gradients:')\n",
    "print('d(output)/d(a) =',mymodel.a.grad)\n",
    "print('d(output)/d(b) =',mymodel.b.grad)\n",
    "print('d(output)/d(input) =',input_data.grad)  \n",
    "\n",
    "# obj = a1*x1 + a2*x2 + b\n",
    "# d(obj)/d(a1) = x1, d(obj)/d(a2) = x2 \n",
    "# d(obj)/d(b) = 1.\n",
    "# d(obj)/d(x1) = a1, d(obj)/d(x2) = a2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf199d3a",
   "metadata": {},
   "source": [
    "###  n-variable input and n-variable output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c708cc87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output = tensor([ 9., 16.], grad_fn=<AddBackward0>) \n",
      "\n",
      "output to calculate grad: tensor([1., 0.]) \n",
      "\n",
      "Gradients:\n",
      "d(output)/d(a) = tensor([4., 0.])\n",
      "d(output)/d(b) = tensor(1.)\n",
      "d(output)/d(input) = tensor([2., 0.])\n"
     ]
    }
   ],
   "source": [
    "class Mymodel(nn.Module): \n",
    "    def __init__(self, a, b):\n",
    "        super().__init__()\n",
    "        self.a = nn.Parameter(torch.tensor(a))\n",
    "        self.b = nn.Parameter(torch.tensor(b))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.a*x + self.b\n",
    "\n",
    "\n",
    "# Instantiate the model\n",
    "mymodel = Mymodel(a = [2.,3.], b = 1.)\n",
    "\n",
    "# Create input and enable gradient calculation\n",
    "input_data = torch.tensor([4.,5.])\n",
    "input_data.requires_grad = True\n",
    "#input_data = torch.tensor([4.,5.], requires_grad = True)\n",
    "\n",
    "# Call the forward model\n",
    "output_data = mymodel(input_data)\n",
    "print('output =', output_data, '\\n')\n",
    "\n",
    "# Choose output -> e.g. torch.tensor([1,0]) or torch.tensor([0,1]); torch.tensor([1,1]) returns sum of grads\n",
    "output_choose = torch.zeros_like(output_data)\n",
    "output_choose[0] = 1 \n",
    "#output_choose[1] = 1\n",
    "print('output to calculate grad:', output_choose, '\\n')\n",
    "\n",
    "# Calculate the gradients\n",
    "mymodel.zero_grad() # Clear any existing gradients\n",
    "output_data.backward(output_choose) \n",
    "print('Gradients:')\n",
    "print('d(output)/d(a) =',mymodel.a.grad)\n",
    "print('d(output)/d(b) =',mymodel.b.grad)\n",
    "print('d(output)/d(input) =',input_data.grad)   \n",
    "\n",
    "# obj1 = a1*x1 + b\n",
    "# obj2 = a2*x2 + b\n",
    "# d(obj1)/d(a1) = x1, # d(obj1)/d(a2) = 0 \n",
    "# d(obj2)/d(a1) = 0,  # d(obj2)/d(a2) = x2 \n",
    "# d(obj1)/d(b) = 1.\n",
    "# d(obj2)/d(b) = 1.\n",
    "# d(obj1)/d(x1) = a1, # d(obj1)/d(x2) = 0 \n",
    "# d(obj2)/d(x1) = 0,  # d(obj2)/d(x2) = a2 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69eb5cd5",
   "metadata": {},
   "source": [
    "### Using torch.autograd.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce35b3d",
   "metadata": {},
   "source": [
    "The difference is that autograd.grad() is returning the gradients to you.\n",
    "While .backward() is populating the .grad field on the different leaf Tensors that were used to compute y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "accbeffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output = tensor([ 9., 16.], grad_fn=<AddBackward0>) \n",
      "\n",
      "output to calculate grad: tensor([1., 0.]) \n",
      "\n",
      "Gradients:\n",
      "d(output)/d(input) = (tensor([2., 0.]),)\n",
      "d(output)/d(input) = None\n"
     ]
    }
   ],
   "source": [
    "class Mymodel(nn.Module): \n",
    "    def __init__(self, a, b):\n",
    "        super().__init__()\n",
    "        self.a = nn.Parameter(torch.tensor(a))\n",
    "        self.b = nn.Parameter(torch.tensor(b))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.a*x + self.b\n",
    "\n",
    "\n",
    "# Instantiate the model\n",
    "mymodel = Mymodel(a = [2.,3.], b = 1.)\n",
    "\n",
    "# Create input and enable gradient calculation\n",
    "input_data = torch.tensor([4.,5.])\n",
    "input_data.requires_grad = True\n",
    "#input_data = torch.tensor([4.,5.], requires_grad = True)\n",
    "\n",
    "# Call the forward model\n",
    "output_data = mymodel(input_data)\n",
    "print('output =', output_data, '\\n')\n",
    "\n",
    "# Choose output -> e.g. torch.tensor([1,0]) or torch.tensor([0,1]); torch.tensor([1,1]) returns sum of grads\n",
    "output_choose = torch.zeros_like(output_data)\n",
    "output_choose[0] = 1\n",
    "output_choose[1] = 0\n",
    "print('output to calculate grad:', output_choose, '\\n')\n",
    "\n",
    "# Calculate the gradients\n",
    "grad = torch.autograd.grad(output_data, input_data, output_choose)\n",
    "print('Gradients:')\n",
    "print('d(output)/d(input) =',grad)   \n",
    "print('d(output)/d(input) =',input_data.grad) # torch.autograd.grad return the gradient do not save it\n",
    "\n",
    "# obj1 = a1*x1 + b\n",
    "# obj2 = a2*x2 + b\n",
    "# d(obj1)/d(x1) = a1, # d(obj1)/d(x2) = 0 \n",
    "# d(obj2)/d(x1) = 0,  # d(obj2)/d(x2) = a2 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
